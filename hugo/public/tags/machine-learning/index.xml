<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning on David Bieber</title>
    <link>https://davidbieber.com/tags/machine-learning/</link>
    <description>Recent content in machine-learning on David Bieber</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://davidbieber.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sleeping with GPT</title>
      <link>https://davidbieber.com/snippets/2023-01-04-sleeping-with-gpt/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2023-01-04-sleeping-with-gpt/</guid>
      
      <description>&lt;p&gt;The last few nights I have been sleeping with GPT, and oh, it has been a joy.&lt;/p&gt;
&lt;h3 id=&#34;background-capturing-my-thoughts-as-i-drift-off-to-sleep&#34;&gt;Background: Capturing my thoughts as I drift off to sleep&lt;/h3&gt;
&lt;p&gt;I use a note-taking device that I call 
&lt;a href=&#34;https://davidbieber.com/projects/go-note-go&#34;&gt;Go Note Go&lt;/a&gt;.
It&amp;rsquo;s a computer keyboard without a screen that I type on to capture my thoughts everywhere, even as I drift off to sleep.
I have one in my bed, and I also keep them on my desk at work and in various spots around my apartment; anywhere an idea strikes, I have a Go Note Go keyboard ready to capture that idea.
Go Note Go&amp;rsquo;s main purpose is to let me quickly jot down these ideas so I can remember them later, e.g. after getting a good night&amp;rsquo;s sleep&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.
It also 
&lt;a href=&#34;https://davidbieber.com/snippets/2023-01-16-go-note-go-features/&#34;&gt;does other things (click for a concise primer on Go Note Go)&lt;/a&gt; like speaking the time aloud or 
&lt;a href=&#34;https://davidbieber.com/post/2022-01-08-new-messager-setup/&#34;&gt;letting me send messages to other people&lt;/a&gt;.
Most recently, I&amp;rsquo;ve added an AI assistant to Go Note Go, and have begun conversing with it as I drift off to sleep.&lt;/p&gt;
&lt;p&gt;Even before adding the AI assistant, Go Note Go had become a staple in my life.
Go Note Go&amp;rsquo;s main capability &amp;ndash; capturing my thoughts &amp;ndash; helps me fall asleep more effectively.
If I have an anxious thought swirling in my brain, I can simply type it into Go Note Go.
Instead of dozens of versions of the thought popping up in my head all night, I have just a single canonical version of the thought stored on the device, and I can fall asleep.&lt;/p&gt;
&lt;p&gt;Go Note Go also supports commands, like reading the time out loud.
Entering a line that starts with a colon (&#39;:&#39;) issues a command.
Typing :r has it read back the last thing I wrote.
Typing :t will have it read the time to me.
I like this because it lets me know the time without having to open my eyes, so getting the time doesn&amp;rsquo;t require being alert&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;All of this lets me drift off to sleep more effectively. I can get ideas out of my head while avoiding things that would wake me up, like looking at my phone or turning on the lights to write down an idea.
Compared with writing on my phone, or a computer, or on paper, writing on Go Note Go is relaxing and doesn&amp;rsquo;t wake me up very much.
So, Go Note Go has become an essential tool in my daily routine, helping me capture and organize my thoughts, and allowing me to relax and fall asleep more easily.&lt;/p&gt;
&lt;h3 id=&#34;adding-an-ai-assistant-to-go-note-go&#34;&gt;Adding an AI assistant to Go Note Go&lt;/h3&gt;
&lt;p&gt;Most recently, I added an AI assistant to Go Note Go and I absolutely love it.&lt;/p&gt;
&lt;p&gt;By default when I type on the keyboard the text just shows up in my notes,
but now I have the option of sending the text off to an AI assistant as well.
Since there&amp;rsquo;s no screen on Go Note Go, the assistant&amp;rsquo;s responses are read out loud.
They&amp;rsquo;re also inserted into my notes for future reference, which I can browse later at a computer or on my phone.&lt;/p&gt;
&lt;p&gt;Most of my Go Note Go usage remains unchanged, but one aspect now feels very different: drifting off to sleep.
This is when having the AI assistant feels most rewarding.&lt;/p&gt;
&lt;h3 id=&#34;sleeping-with-gpt-what-do-we-discuss&#34;&gt;Sleeping with GPT: What do we discuss?&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m lying there in the bed, but I&amp;rsquo;m not really trying to go to sleep.
I&amp;rsquo;m excited that I have this new AI with me which I can ask anything at all.
I&amp;rsquo;ve been meaning to learn organic chemistry but haven&amp;rsquo;t found the time; this seems a perfect opportunity to get started.
On the first night I drift off to sleep peppering the AI with questions about organic chemistry and battery technology.
On subsequent nights I probe new topics, trying to get a deeper understanding of the superficial things I learned the night before, and also introducing new topics to our discussions.
I continue peppering the AI with questions about chemistry and history as I drift off to sleep.
Quickly realizing that this could inhibit my ability to get a good night&amp;rsquo;s sleep, I also ask for advice in that regard, and it obliges.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s clear from the outset that I&amp;rsquo;m going to want to write about this, so I&amp;rsquo;m jotting down notes for this very post. I ask my assistant to turn my notes into an outline. That outline is read out loud, and it&amp;rsquo;s also sitting there for me the next day when I go to start writing in earnest.&lt;/p&gt;
&lt;p&gt;In the morning, when I wake up, I ask for strategies for a morning routine. It makes good suggestions.
Though the response is nothing that you wouldn&amp;rsquo;t find from a quick Google search for morning routine ideas, the proximity to those ideas as I&amp;rsquo;m just waking up, casually typing to my keyboard, makes them more actionable. The suggestions are things like making my bed right away, drinking a glass of lemon water, and doing some exercise to get my blood flowing. It feels inspiring and healthy.&lt;/p&gt;
&lt;p&gt;One night I asked the AI assistant to read me a bedtime story. I gave it some details about my own life first and it used them to construct a story that was personal and meaningful to me, albeit a bit silly.&lt;/p&gt;
&lt;!-- Other benefits of the assistant: reading back capturing notes and answering questions about them. --&gt;
&lt;h3 id=&#34;trust-and-confidence&#34;&gt;Trust and Confidence&lt;/h3&gt;
&lt;p&gt;An invitation into one&amp;rsquo;s bed requires a certain level of trust.&lt;/p&gt;
&lt;p&gt;However, a common criticism of GPT and language models more broadly is that they are often factually inaccurate. What&amp;rsquo;s worse is that when they are wrong, they often are wrong with confidence.&lt;/p&gt;
&lt;p&gt;This makes learning about new topics like battery technology and organic chemistry a challenge.
I don&amp;rsquo;t know if the things that I have learned these last few nights are true or not.
In fact, I know that some of them are definitely not true, because GPT will sometimes flatly contradict itself.&lt;/p&gt;
&lt;p&gt;In spite of this, I&amp;rsquo;ve had the distinct feeling that I have been learning a lot from these night time question peppering sessions.
Is this feeling valid, or have I been duped by the AI?&lt;/p&gt;
&lt;p&gt;To suss out truth from fiction, my first line of defense is my intuition.
Using my own limited knowledge of the topic we are discussing, I can sometimes tell if the model is fibbing.
If what the model says fits nicely into my world model, I might trust it and move on.
When things don&amp;rsquo;t make sense to me, I can ask for explanations or ask pointed questions to dive into the details.
These will quickly seem inconsistent, either with each other or with what I already know, if in fact the model has made up inaccurate information.
(This observation should motivate new, fully automated, methods for discovering truth in these models as well. For example the line of reasoning that 
&lt;a href=&#34;https://arxiv.org/abs/2205.11822&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Maieutic Prompting&lt;/a&gt; pursues proceeds along these lines.)&lt;/p&gt;
&lt;p&gt;This ability to dive deep into the details, sometimes asking extremely basic questions that I would be embarrassed to ask a human, points to a different kind of trust that I do have for the model.&lt;/p&gt;
&lt;h3 id=&#34;a-different-kind-of-trust&#34;&gt;A Different Kind of Trust&lt;/h3&gt;
&lt;p&gt;While I cannot trust the AI to produce factual statements consistently, it has earned my trust in a different way.
I can be uninhibited with GPT.&lt;/p&gt;
&lt;p&gt;I can ask naive questions, things that I would feel embarrassed to ask a human. I can ask &amp;ldquo;why&amp;rdquo; about the most trivial things, the way a 3-year old might, to discover more about the world.
I don&amp;rsquo;t feel any concern that the model will judge me for not knowing something, or not understanding something quickly.
I can ask the same question repeatedly, without concern for taking up its time, or that it has better places to be.
The AI is infinitely patient with me.
I don&amp;rsquo;t worry about how it will feel if I doubt what it&amp;rsquo;s telling me, and express skepticism.&lt;/p&gt;
&lt;p&gt;In these ways, it is an ideal tutor. By giving me the freedom to explore the topics that interest me, the things I&amp;rsquo;m learning about feel truly connected to one another, rather than ad hoc and unrelated to my interests as they might if I were following a curriculum not tailored to my needs and interests. It would be better, of course, if I could trust it to be factually accurate.&lt;/p&gt;
&lt;p&gt;As a brief aside: I think this experience &amp;ndash; interacting with an AI tutor, guided by a curriculum and standards, but free to wander through information space as it pleases the user, is going to be central to education in the future. I&amp;rsquo;m excited to explore the space of possible AI-centric classroom and education designs, to find novel ways of learning jointly with humans and AIs, and I intend to do so further in future snippets.&lt;/p&gt;
&lt;p&gt;Why can I be so free with GPT in ways that I cannot be with a human? I can identify a few reasons.&lt;/p&gt;
&lt;p&gt;The machine&amp;rsquo;s statelessness / resetability is one key component. It isn&amp;rsquo;t learning about me, forming long term judgements. If I reveal that I don&amp;rsquo;t know some &amp;ldquo;simple&amp;rdquo; concept, like what an ionic bond is, it isn&amp;rsquo;t going to retain that information and shape our future interactions based on it. The next conversation I have with the assistant will be tabula rasa, starting from a blank slate.&lt;/p&gt;
&lt;p&gt;Its isolation from others is another factor. I can confide in it, and it isn&amp;rsquo;t going to gossip or reveal anything I tell it to another human. Sure, I have concerns that OpenAI gets access to whatever I send to the assistant, and this could show up in training data or in front of human evaluators as a result. Nevertheless, it feels private, like no one in my life would see the things I write.&lt;/p&gt;
&lt;p&gt;I think there&amp;rsquo;s a third trait that aids in creating this kind of trust that&amp;rsquo;s harder to pin down. Something about the inhuman form factor &amp;ndash; something about how it feels like talking to a machine &amp;ndash; enables the comfort level and vulnerability I&amp;rsquo;ve expressed feeling above.&lt;/p&gt;
&lt;h3 id=&#34;learning-about-chloropropane-an-illustration-of-trust-and-distrust&#34;&gt;Learning about Chloropropane: An Illustration of Trust and Distrust&lt;/h3&gt;
&lt;p&gt;I asked the AI to give me an example of an organic chemistry homework problem. It asked me a question about chloropropane.&lt;/p&gt;
&lt;p&gt;I asked what chloropropane is used for. It told me it&amp;rsquo;s used as a pesticide.&lt;/p&gt;
&lt;p&gt;I asked if it&amp;rsquo;s used as a pesticide. It told me no.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve reproduced our conversation(s) below. The timestamps indicate separate &amp;ldquo;sessions&amp;rdquo;, meaning that each timestamped conversation is independent of the others. The AI had no way of looking at what was said in an earlier session. As you expand the sections, see the self-contradictions &lt;mark&gt;highlighted in yellow&lt;/mark&gt;.&lt;/p&gt;
&lt;style&gt;
details {
  margin-left: 2em;
}

summary {
  margin-left: -2em;
}
&lt;/style&gt;
&lt;p&gt;&lt;button id=&#34;expand-button&#34; onclick=&#34;expandCollapseAll()&#34;&gt;Expand All&lt;/button&gt;&lt;/p&gt;
&lt;script&gt;
  var expandButton = document.getElementById(&#39;expand-button&#39;);
  var isExpanded = false;

  function expandCollapseAll() {
    var detailsElements = document.getElementsByTagName(&#39;details&#39;);
    for (var i = 0; i &lt; detailsElements.length; i++) {
      detailsElements[i].open = !isExpanded;
    }
    isExpanded = !isExpanded;
    expandButton.textContent = isExpanded ? &#39;Close All&#39; : &#39;Expand All&#39;;
  }
&lt;/script&gt;
&lt;details&gt;
  &lt;summary&gt;00:47 AM&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;Give me a organic chemistry homework problem&lt;/summary&gt;
      Calculate the enthalpy of combustion for 1-chloropropane in kJ/mol.
  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;What does that mean?&lt;/summary&gt;
      Enthalpy of combustion is the amount of energy released when a compound is completely burned in oxygen. In this case, you will be calculating the amount of energy released when 1-chloropropane is completely burned in oxygen, expressed in units of kilojoules per mole (kJ/mol).
  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;What is chloropropane used for?&lt;/summary&gt;
      Chloropropane is used as a precursor to other chemicals in the production of materials such as plasticizers, solvents, and lubricants. It is also &lt;mark&gt;used as a pesticide&lt;/mark&gt; in agriculture.
  &lt;/details&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;00:48 AM&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;Is chloropropane a pesticide?&lt;/summary&gt;
      No, chloropropane is &lt;mark&gt;not a pesticide&lt;/mark&gt;. It is a colorless gas with a strong odor, used mainly in the production of other chemicals and in the &lt;mark&gt;manufacture of rubber&lt;/mark&gt; and plastics.
  &lt;/details&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;00:49 AM&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;Is chloropropane used for making rubber?&lt;/summary&gt;
      No, chloropropane is &lt;mark&gt;not used for making rubber&lt;/mark&gt;.
  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;What is it for?&lt;/summary&gt;
      Chloropropane is an industrial chemical used in the production of other chemicals including agrochemicals, pharmaceuticals, and &lt;mark&gt;dyes&lt;/mark&gt;.
  &lt;/details&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;00:50 AM&lt;/summary&gt;
    &lt;details&gt;
    &lt;summary&gt;Is chloropropane used in the production of dyes?&lt;/summary&gt;
      No, chloropropane is &lt;mark&gt;not used in the production of dyes&lt;/mark&gt;.
    &lt;/details&gt;
    &lt;details&gt;
    &lt;summary&gt;What is it used for?&lt;/summary&gt;
      Chloropropane is a chemical compound used as a solvent and intermediate in the production of a variety of products, including pharmaceuticals, pesticides, and other chemicals.
      Chloropropane is &lt;mark&gt;used as a solvent&lt;/mark&gt; in organic synthesis and in the production of pharmaceuticals, agrochemicals, and other chemicals.
    &lt;/details&gt;
    &lt;details&gt;
    &lt;summary&gt;Is chloropropane used in the production of pesticides?&lt;/summary&gt;
      No, chloropropane is &lt;mark&gt;not used in the production of pesticides&lt;/mark&gt;.
    &lt;/details&gt;
    What is it used for?
  &lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;00:51 AM&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;Is chloropropane a solvent?&lt;/summary&gt;
      No, chloropropane is &lt;mark&gt;not a solvent&lt;/mark&gt;.
  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;What is it used for?&lt;/summary&gt;
      Chloropropane is used as an intermediate in the production of solvents, pesticides, pharmaceuticals and other chemicals. It is also used as a refrigerant and as a propellant in aerosols.
  &lt;/details&gt;
&lt;/details&gt;
&lt;p&gt;You can see the AI blatantly contradicts itself repeatedly, and confidently so.&lt;/p&gt;
&lt;p&gt;While this conversation illustrates how I cannot trust the AI to be factual,
it also demonstrates the kind of trust that I do have for the AI.
It blatantly contradicted itself, yet I felt comfortable probing the depths of its knowledge,
asking questions in a volume that I would not have been comfortable asking of a human.&lt;/p&gt;
&lt;h3 id=&#34;strategies-for-mitigating-the-ais-fibs&#34;&gt;Strategies for mitigating the AI&amp;rsquo;s fibs&lt;/h3&gt;
&lt;p&gt;I didn&amp;rsquo;t get the AI to stop making things up. And I didn&amp;rsquo;t get it to admit uncertainty when it doesn&amp;rsquo;t know things.
But a few mitigation strategies did arise for dealing with the AI&amp;rsquo;s fibbing tendency.&lt;/p&gt;
&lt;p&gt;One was to probe the AI about topics I already know about in order to understand its limitations.
I had it teach me about math and algorithms concepts I was already quite familiar with.
My thinking here was that this would help me develop my intuition for what it&amp;rsquo;s like when it&amp;rsquo;s fibbing,
so I could better deal with
the inaccuracies on topics I&amp;rsquo;m less familiar with.&lt;/p&gt;
&lt;p&gt;A second mitigation that quickly became essential was having detailed records of what the AI said.
While I was drifting off to sleep, the AI might tell me something wrong and then contradict itself a minute later.
Without the record to verify this, the confidence of the contradiction would have a gas-lighting effect on me.
I might question myself &amp;ndash; did I remember the AI correctly?
Being able to see the contradiction highlighted, as above, helped keep me sane in the face of the AI&amp;rsquo;s unearned and contradictory confidence.&lt;/p&gt;
&lt;p&gt;Having the permanent record also allows me to look up the truth the next day, to find out how much of what I learned had basis in reality.&lt;/p&gt;
&lt;h3 id=&#34;other-benefits-of-having-the-ai-with-me&#34;&gt;Other benefits of having the AI with me&lt;/h3&gt;
&lt;p&gt;Central to Go Note Go&amp;rsquo;s design is that it has no screen. This is a purposeful choice, and enables so much of what I love about Go Note Go. However, sometimes I miss being able to see what I&amp;rsquo;ve written. This is where the assistant comes in.&lt;/p&gt;
&lt;p&gt;First though I must emphasize that on the whole, I actually really like that the lack of screen prevents me from wasting time rereading what I&amp;rsquo;ve written. But when I lose my train of thought entirely, it would be nice to remember what I wrote last.
For this, I can ask the assistant to read back what I wrote last, or even to summarize it concisely. If my mind has wandered and I want to continue typing where I left off, this feature is quite welcome!&lt;/p&gt;
&lt;p&gt;In this way, the AI compensates for the lack of screen.
It&amp;rsquo;s behaving somewhat like an intelligent screen reader.
With typical screen readers, navigation is performed spatially, and the reader speaks text at the indicated location. With the AI assistant, &amp;ldquo;navigation&amp;rdquo; is performed via a textual query, and the response can either be verbatim or an intelligent response like a summary or answer. I suspect AI assistants will quickly change the way accessibility technology operates, if they haven&amp;rsquo;t already done so.&lt;/p&gt;
&lt;h3 id=&#34;what-dont-you-send-to-the-ai&#34;&gt;What don&amp;rsquo;t you send to the AI?&lt;/h3&gt;
&lt;p&gt;As I drift off to sleep, I enter thoughts about a wide range of subjects that I don&amp;rsquo;t send to the AI assistant too. A quick scan of my recent Go Note Go writing (just from the last couple days, all since adding the assistant) shows the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plans for my upcoming California trip&lt;/li&gt;
&lt;li&gt;Observations about Go Note Go &amp;ndash; both improvements I&amp;rsquo;m looking forward to making and emergent behaviors I&amp;rsquo;m excited to share in future writing&lt;/li&gt;
&lt;li&gt;Thoughts about the future of AI&lt;/li&gt;
&lt;li&gt;Machine learning experiments I&amp;rsquo;m excited to run&lt;/li&gt;
&lt;li&gt;Thoughts I&amp;rsquo;d like to publish about, such as the unexpected dangers of reducing friction, or the less-appreciated benefits of repetition&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://twitter.com/Bieber&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tweet ideas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Items I intend to buy&lt;/li&gt;
&lt;li&gt;Questions I want to ask either specific people, or the internet at large&lt;/li&gt;
&lt;li&gt;Lists of todos for the next day&lt;/li&gt;
&lt;li&gt;Reflections on the day&lt;/li&gt;
&lt;li&gt;Ideas to try, e.g. for technical problems I ran into that day&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The AI assistant merely augments my existing Go Note Go usage,
but hasn&amp;rsquo;t replaced it. 
&lt;a href=&#34;https://davidbieber.com/snippets/2023-01-16-go-note-go-features/&#34;&gt;All of Go Note Go&amp;rsquo;s other features&lt;/a&gt; &amp;ndash; particularly its always-on ability to quickly capture thoughts anywhere &amp;ndash; remain the driving reason I use Go Note Go so much.&lt;/p&gt;
&lt;h3 id=&#34;what-worked-well&#34;&gt;What worked well?&lt;/h3&gt;
&lt;p&gt;The best part of this process was being able to learn what I want to learn when I want to learn it.
While a deep probe into a topic inevitably turned up falsehoods, overall asking questions about things I was curious about worked really well.&lt;/p&gt;
&lt;p&gt;And I think about things differently at night. My brain processes topics that it hasn&amp;rsquo;t had a chance to think on throughout the day. It comes up with things it wants to do that it doesn&amp;rsquo;t come up with when it&amp;rsquo;s otherwise occupied throughout the day.&lt;/p&gt;
&lt;p&gt;I think of things I want to write, and the assistant helps me think through them and outline them.&lt;/p&gt;
&lt;p&gt;I think of people I want to reach out to. With Go Note Go, I can write them a message and approve it to send in the morning. (The assistant doesn&amp;rsquo;t really play a role here, but I thought I&amp;rsquo;d mention it anyway.)&lt;/p&gt;
&lt;p&gt;I think of things I want to know, and the assistant helps answer my questions.&lt;/p&gt;
&lt;p&gt;I think of ideas I want to try. Some of them I can try with the assistant, and others I just jot down to return to later.&lt;/p&gt;
&lt;p&gt;In many of these instances, the value of the AI assistant is that I can offload some of my thinking to it. It isn&amp;rsquo;t necessarily producing insights that I wouldn&amp;rsquo;t have come up with on my own, but it&amp;rsquo;s allowing me a moment&amp;rsquo;s rest while it does the thinking on my behalf. Then I can start from its thoughts as a baseline and build from there, higher than I could build on my own. On many other occasions, it genuinely surprises me with its good ideas.&lt;/p&gt;
&lt;p&gt;On a couple of nights, the AI took me exploring imaginary worlds. Similar to a text adventure game, it described my environment to me, and I gave it instructions like talking to a person, or exploring a building. With my eyes closed and my brain on the edge of sleep, it felt like dreaming while I was still awake and I quite enjoyed it.&lt;/p&gt;
&lt;h3 id=&#34;things-that-didnt-work-so-well&#34;&gt;Things that didn&amp;rsquo;t work so well&lt;/h3&gt;
&lt;p&gt;The main drawback of this system is the lack of trust in the accuracy of the AI&amp;rsquo;s statements, particularly when I&amp;rsquo;m trying to learn.
Other limitations were subtler and less dampening for the experience.&lt;/p&gt;
&lt;p&gt;When I tried to get it to teach me math, my 
&lt;a href=&#34;https://espeak.sourceforge.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;text to speech system (espeak)&lt;/a&gt; did quite poorly on reading the math aloud.
I would love to replace the text to speech system with one with better prosody and better math support.
Ideally, the text to speech system would speak with 
&lt;a href=&#34;https://www.youtube.com/watch?v=Qe6o9j4IjTo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Grant Sanderson&amp;rsquo;s voice and cadence&lt;/a&gt;, and handle math notation seamlessly.
While this seems a cosmetic change, it does impact the set of topics I can discuss cleanly with the AI as I drift off.&lt;/p&gt;
&lt;p&gt;The dependence on an internet connection was another small drawback. I take my Go Note Go into the woods, used it during an Uber ride the airport today, and regularly use it when I fly. The AI assistant doesn&amp;rsquo;t work in these situations (the rest of Go Note Go continues to work fine) since it depends on having internet access. For a capability that is simple enough to not require AI, like reading back the topics I&amp;rsquo;ve written about recently, it feels quite silly to lose the capability when the internet is gone.&lt;/p&gt;
&lt;p&gt;Related to the internet dependence, the lack of privacy from OpenAI is another important drawback to me. The thoughts I produce as I drift off to sleep are deeply personal! I would much prefer not to send them off to OpenAI (the current version of the assistant is implemented with text-davinci-003).&lt;/p&gt;
&lt;p&gt;Finally, there&amp;rsquo;s another significant drawback, one you might have already picked up on: talking with an AI can get in the way of falling asleep.
I view talking with an AI while drifting off to sleep similarly to listening to reading a book, listening to an audiobook, or to a podcast before bed.
These activities require some amount of thought, but can also help to wind down and fall asleep.
Talking to the AI required no monitor, and hence to blue lights that can make falling asleep harder.
It simply requires some amount of restraint to stop the conversation and transition to sleep, just as one must put down a book and close their eyes if reading before bed.&lt;/p&gt;
&lt;p&gt;You can see in the chloropropane conversation reproduced above from the timestamps that I was talking to the AI at nearly 1am. I like to go to sleep 
&lt;a href=&#34;https://davidbieber.com/snippets/2021-04-20-sleep-no-snippet/&#34;&gt;closer to 10:10pm&lt;/a&gt;, so clearly this drawback is real for me.&lt;/p&gt;
&lt;h3 id=&#34;it-left-me-wanting-more&#34;&gt;It left me wanting more&lt;/h3&gt;
&lt;p&gt;Having an assistant as I drifted off to sleep was great overall, even in spite of these drawbacks.
I was definitely left with a sense of wanting more though.&lt;/p&gt;
&lt;p&gt;I want more assistance from my assistant.
I want to be able to query my complete history of notes, asking questions like &amp;ldquo;What are some ideas I keep returning to?&amp;rdquo; or &amp;ldquo;Bring up all my outstanding Go Note Go TODOs.&amp;rdquo;
Perhaps I&amp;rsquo;ll be able to implement this with 
&lt;a href=&#34;https://gpt-index.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-Index&lt;/a&gt;, or a 
&lt;a href=&#34;https://arxiv.org/abs/2203.08913&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Memorizing Transformer&lt;/a&gt;, but for now I do without.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d also love for my assistant to be able to take actions on my behalf. Maybe I can integrate 
&lt;a href=&#34;https://www.adept.ai/act&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adept AI&amp;rsquo;s action transformer&lt;/a&gt; into my next iteration to achieve this. For example, I want to be able tell the assistant my shopping list, and have it populate my Amazon cart. Then, when I&amp;rsquo;m back at a computer, I can review the cart and click submit, saving myself time shopping.&lt;/p&gt;
&lt;p&gt;Sometimes (albeit rarely :P) I&amp;rsquo;m not at a Go Note Go, but I still want to talk to my AI assistant.
For that, I&amp;rsquo;ve used Twilio so I can call my assistant on the phone.
I use this when I&amp;rsquo;m driving or walking around. But that is a subject for another post entirely.&lt;/p&gt;
&lt;h3 id=&#34;concluding-remarks&#34;&gt;Concluding remarks&lt;/h3&gt;
&lt;p&gt;Adding an AI assistant to Go Note Go has been an absolute joy and I continue to use it almost every night.
Despite its tendency to make things up &amp;ndash; or more charitably, to hallucinate &amp;ndash; it has still earned my trust in a more visceral way.
I&amp;rsquo;m curious to see what use cases persist after I&amp;rsquo;ve had this capability for a longer period of time.&lt;/p&gt;
&lt;p&gt;Of course, the AI assistant is not the only reason that Go Note Go is such a critical component in my life.
Go Note Go can do so much more &amp;ndash; 
&lt;a href=&#34;https://davidbieber.com/snippets/2023-01-16-go-note-go-features/&#34;&gt;a complete and concise overview of its capabilities is here&lt;/a&gt; &amp;ndash;
like letting me 
&lt;a href=&#34;https://davidbieber.com/post/2022-01-08-new-messager-setup/&#34;&gt;send messages as I drift off to sleep&lt;/a&gt; and helping me 
&lt;a href=&#34;https://davidbieber.com/post/2022-02-07-keyboards-everywhere/&#34;&gt;reclaim my attention in a world full of distractions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the AI assistant added in, however, I feel like I have a new superpower. I can offload computation from my brain to it, and explore worlds of thought I could never have entered on my own.&lt;/p&gt;
&lt;p&gt;Go Note Go is also 
&lt;a href=&#34;https://github.com/dbieber/GoNoteGo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;completely open source&lt;/a&gt;. I encourage the hacker-tinkerers among you to join me in the world of headless computing and try it for yourself.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Anything I type on this keyboard gets automatically uploaded to my notes as soon as the keyboard is in range of wifi. This allows for offline usage, e.g. while driving or camping. These were the two use-cases that inspired me to build the device. Now my main use-case is capturing ideas while drifting off to sleep.
It also has a microphone, so if speaking feels like it would take less energy than talking, I can speak my notes instead. This feature is what enables the driving use case, as of course I don&amp;rsquo;t type while I drive! &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;If I prefer speaking, I can also trigger these commands with the hot word &amp;ldquo;go go&amp;rdquo;, e.g. saying &amp;ldquo;go go time&amp;rdquo; gets the time. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Thoughts on ChatGPT</title>
      <link>https://davidbieber.com/snippets/2022-12-08-thoughts-on-chatgpt/</link>
      <pubDate>Thu, 08 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2022-12-08-thoughts-on-chatgpt/</guid>
      
      <description>&lt;p&gt;This blog post was entirely written by me, David Bieber, a human being. I did not consult with ChatGPT or Bieber Bot or any other assistants or conversational agents in the writing of this post. It is likely this will now be a rare occurrence, and that subsequent posts will generally be written with an assistant at my side.&lt;/p&gt;
&lt;h2 id=&#34;reminder-this-is-a-snippet&#34;&gt;Reminder: This is a snippet&lt;/h2&gt;
&lt;p&gt;If this were an ordinary blog post, I might set aside some space to bring you up to speed with what ChatGPT is (it&amp;rsquo;s a conversational assistant &amp;ndash; a chatbot &amp;ndash; but more sophisticated than SmarterChild ever dreamed she could be). But this is a snippet, a mini blog post written for no audience and with no quality bar to publication, so I will press on without doing so.&lt;/p&gt;
&lt;h2 id=&#34;reactions-to-chatgpt&#34;&gt;Reactions to ChatGPT&lt;/h2&gt;
&lt;p&gt;Futility. Existential dread. Unsettled. Excitement! There are lots of possible reasons one might be concerned about the release of ChatGPT by OpenAI. For me, the ones that hit me hardest were about my own ability to stay relevant a few years down the line. Bear in mind, when you hear this concern, that it&amp;rsquo;s not just about ChatGPT&amp;rsquo;s current capabilities. It&amp;rsquo;s about the expected advancements that are coming in the next several months or years.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not concerned about being &amp;ldquo;replaced&amp;rdquo; wholesale. I am concerned about my own ability to stay relevant and continue to provide (as significant) value professionally and personally a few year&amp;rsquo;s down the line, heightening competition and expectations, a future need to be always on / always adapting to a world changing faster each year. An economic future full of contradictions I haven&amp;rsquo;t been able to wrap my head around yet. And a large number of people who are going to have sudden shifts in their lives, jobs, etc.&lt;/p&gt;
&lt;p&gt;I previously thought self-driving trucks would be the one Big Shock, and everything else would get automated more gradually (in terms of people/year). I&amp;rsquo;m in the process of reconsidering.&lt;/p&gt;
&lt;h2 id=&#34;expected-advancements&#34;&gt;Expected Advancements&lt;/h2&gt;
&lt;p&gt;Future capabilities will include 
&lt;a href=&#34;https://openai.com/blog/webgpt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;web browsing&lt;/a&gt;, 
&lt;a href=&#34;https://www.adept.ai/act&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;taking actions&lt;/a&gt; on your computer, and accessing your personal files (documents, emails, chats, etc) (with your permission, of course). We&amp;rsquo;re also going to see major improvements in quality from human feedback, and from a larger model trained on more data. I expect this is coming quite soon. A bit further down the line, integration of multiple modalities (e.g. image generation, audio, video) will come too.&lt;/p&gt;
&lt;h2 id=&#34;using-chatgpt-with-my-roam-research-notes&#34;&gt;Using ChatGPT with my Roam Research Notes&lt;/h2&gt;
&lt;p&gt;I use 
&lt;a href=&#34;https://davidbieber.com/projects/go-note-go&#34;&gt;Go Note Go&lt;/a&gt; to jot down miscellaneous thoughts. They are often scattered and always ill-formatted. ChatGPT is able to pull out a clean list of TODOs from my notes, unperturbed by the messy format they start in. Integrating conversational assistants into more of my personal documents is going to be immensely valuable. Excited to see what progress on retrieval augmented models brings next year.&lt;/p&gt;
&lt;h2 id=&#34;building-products-with-chatgpt&#34;&gt;Building Products with ChatGPT&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Voice assistant:&lt;/strong&gt; Tonight I prototyped a voice conversational assistant with Twilio using GPT-3.5 (davinci-text-003). I&amp;rsquo;m excited to try it out with ChatGPT as well. Being able to place a phone call to use the power of a conversational assistant is convenient, especially when driving. There, a phone call is easy but a text based app is not safe.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Medical robo-intake:&lt;/strong&gt; At the doctor&amp;rsquo;s office, you typical fill out an intake form which is impersonal. Then, if the doctor is busy, you may not get to tell them all the details that could be relevant to your case. Using a conversational assistant to perform the medical intake could be quite valuable. We wouldn&amp;rsquo;t be relying on the AI to have robust medical knowledge or make any diagnosis; it would simply ask relevant questions to try to elicit any details that might be pertinent for the doctor to know. The doctor could still see the full conversation, as well as a robo-summary with the highlights.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Personal tutor:&lt;/strong&gt; One drawback of the current ChatGPT system is it isn&amp;rsquo;t always factual, making it challenging to use for learning unfamiliar subject matter. I envision a system in which a human tutor can view their student&amp;rsquo;s conversations with an AI-tutor, and can jump in with corrections and suggestions when needed. Another important aspect of an AI personal tutor will be curriculum setting (involving push messages, not just reactive messages), and goal setting, but the most important aspect is just that you can go down whatever rabbit-hole tangents catch your eye while progressing through the guided lessons.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Teddy Bear Programmer:&lt;/strong&gt; ChatGPT already provides a great developer experience, where you can ask it technical questions or to perform code-writing tasks. To improve this experience, we can build a system where it always has visibility into the context of your development efforts. E.g. it can see your recent terminal usage or your current editor window. So when you ask it questions, it knows why you&amp;rsquo;re asking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The &amp;ldquo;Clink&amp;rdquo; Feature for Go Note Go:&lt;/strong&gt; The idea here is that when you take notes on Go Note Go, and someone else also has taken notes, you should be able to &amp;ldquo;clink&amp;rdquo; your two note-bases in order to find points of commonality between you. Then you can hit it off and discuss your common interests! The ChatGPT tech makes implementing this easier.&lt;/p&gt;
&lt;h2 id=&#34;my-own-uses-of-chatgpt-so-far&#34;&gt;My Own Uses of ChatGPT so Far&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Writing a legal document&lt;/strong&gt; for a car sharing agreement for my partner.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Writing a blog post&lt;/strong&gt; on 
&lt;a href=&#34;https://davidbieber.com/snippets/2022-12-03-spicy-conversations/&#34;&gt;the salt, fat, acid, heat metaphor&lt;/a&gt;. Revising the post was done with the help of ChatGPT as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning&lt;/strong&gt; about variational autoencoders, about music theory, violin and guitar, and about Rust and building Chrome Extensions, and about topics in medicine, history, and science.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Programming&lt;/strong&gt; in languages I&amp;rsquo;m less familiar with and using APIs I&amp;rsquo;m unfamiliar with.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reading papers&lt;/strong&gt; and having ChatGPT summarize sections as I read them. Similarly, having ChatGPT summarize websites and blog posts as I browse the internet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Extracting clean TODOs&lt;/strong&gt; from my messy Go Note Go notes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generating descriptions&lt;/strong&gt; for Stable Diffusion, which in turn generates stunning imagery.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Brainstorming&lt;/strong&gt; uses of ChatGPT, questions to ask people, thoughts on education and psychology, topics in medicine, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Just for fun&lt;/strong&gt; generating simple stories, bad jokes, poor stand up comedy routines, and silly parody songs.&lt;/p&gt;
&lt;h2 id=&#34;excitement-for-the-future&#34;&gt;Excitement for the future&lt;/h2&gt;
&lt;p&gt;Despite my visceral reactions of futility and existential dread noted above&amp;hellip; I&amp;rsquo;m excited and energized for the future. There&amp;rsquo;s no doubt this technology is going to provide a tremendous amount of value and it&amp;rsquo;s going to come quick.
Yes, the space of possible futures seems narrower today than it did before the ChatGPT launch.
Now we must aim for the best possible future among all those that remain open.
And ultimately, does not every passing moment narrow the space of possible futures?
The space of &lt;em&gt;proximal&lt;/em&gt; possible futures, on the other hand, has now been pried wide open.
Machine-learning driven conversational assistants present so many possibilities.
My brainstormings so far only scratch the surface.
I&amp;rsquo;m excited to get building, and to unearth more about what this tech is doing to our future.&lt;/p&gt;
&lt;p&gt;(Want to build together? Get in touch!)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dealing with Giant Group Chats</title>
      <link>https://davidbieber.com/snippets/2022-07-05-giant-group-chats/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2022-07-05-giant-group-chats/</guid>
      
      <description>&lt;p&gt;Sometimes &amp;ndash; usually because of Alex K Chen &amp;ndash; I am added to a giant group chat (GGC).
Today it was a 200+ person highly active chat with folks talking about AI programming tools, aging, and movies.
I love being added to such a chat. It makes me feel thought of, and my opinions respected. So, do keep adding me to GGCs.
However, with being added to a GGC comes some struggles. I haven&amp;rsquo;t fully figured out how to handle a GGC just yet.&lt;/p&gt;
&lt;p&gt;I think some people handle these situations in a more natural way than myself. Here&amp;rsquo;s what I imagine. They&amp;rsquo;re doing something else on the computer, messages are open in the background or in a side window. If they have a conversation-adjacent thought, they share it. If they see a message that looks interesting, they read it. Otherwise, they do their other activities and get on with their life.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If they have a conversation-adjacent thought, they share it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This part is Struggle #1.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If they see a message that looks interesting, they read it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This part is Struggle #2.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;struggle-1-sharing-thoughts-casually-in-a-200-person-setting&#34;&gt;Struggle #1: Sharing thoughts casually in a 200+ person setting&lt;/h3&gt;
&lt;p&gt;Why is this a struggle? I think slowly. I edit. I rethink relevance as the conversation moves away.
The hypothetical person who handles GCCs as described above &amp;ldquo;just&amp;rdquo; types and hits enter, relatively unencumbered.
I think about the permanence of putting something on the internet.
I think about confidentiality of work-adjacent stuff.
I think about whether what I&amp;rsquo;m saying is true, and about how true it is.
This kind of thought can make participation a challenge.&lt;/p&gt;
&lt;h3 id=&#34;struggle-2-staying-abreast-of-200-messages-per-hour&#34;&gt;Struggle #2: Staying abreast of 200 messages per hour&lt;/h3&gt;
&lt;p&gt;I don&amp;rsquo;t want to read all these messages.
They glimmer and my attention is drawn to them, but that doesn&amp;rsquo;t reflect my conscious decision making.
I&amp;rsquo;d much rather read a summary of the messages or a digest of the topics discussed once a week or so.
Then, only if a topic of interest was discussed, I might want to dive deeper and read the individual messages, and
contemplate leaving a reply.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;tooling-for-struggle-1&#34;&gt;Tooling for Struggle #1&lt;/h3&gt;
&lt;p&gt;tl;dr Draft messages outside of conversation UI. Use &amp;ldquo;approve for dealyed send&amp;rdquo; model for sending messages.&lt;/p&gt;
&lt;p&gt;Struggle #1 is a personal psychological struggle.
It isn&amp;rsquo;t first and foremost something for which tooling seems relevant.
If I&amp;rsquo;m not comfortable sharing something with 200 people in a chat, why would tooling change that?
Well, as I&amp;rsquo;ve learned from adding 
&lt;a href=&#34;https://davidbieber.com/post/2022-01-08-new-messager-setup/&#34;&gt;Messager in Go Note Go&lt;/a&gt; tooling can actually make a huge difference in this type of space.
If instead of feeling like I&amp;rsquo;m sending a message to a massive group, I instead feel like I&amp;rsquo;m writing a draft of my thoughts, something I&amp;rsquo;ll maybe send later but maybe not, suddenly it becomes so much easier to write.
And then, once it&amp;rsquo;s written, it also becomes much easier to send.
This is the same lesson I&amp;rsquo;ve learned over and over with snippets since I initially decided to set up this system as 
&lt;a href=&#34;https://davidbieber.com/snippets/2019-12-30-writing-for-no-audience/&#34;&gt;writing for no audience&lt;/a&gt; back in 2019.&lt;/p&gt;
&lt;p&gt;So, what would the tooling look like for dealing with Struggle #1 in GGCs?
I would click a message to start drafting a response,
it would copy the message and context into an editor &amp;ndash; Roam Research, say &amp;ndash; and maybe even stick in the template for writing a snippet.
Then, completely outside the context of the group thread I could compose my thoughts.
If I decide to share it back to the group, great.
If I decide to instead post that thought as a snippet, great.
And if it remains relegated to my notes forever and never sees the light of day, that&amp;rsquo;s a fine outcome too.&lt;/p&gt;
&lt;p&gt;[Aside: The acceptability of that outcome is what makes the writing easier. The very possibility of that outcome diminishes the possibility of that outcome by making the other outcomes more likely. It&amp;rsquo;s the opposite of a self-fulfilling prophecy. A self-fulfilling prophesy is an expectation whose existence leads to its own fulfillment; this is an expectation whose very existence works to prevent its fulfillment.]&lt;/p&gt;
&lt;p&gt;One of the lessons I learned from my Go Note Go messager-queue was the value of the &amp;ldquo;approve for delayed send&amp;rdquo; model.
Psychologically it was easier for me to mark a message as approved for sending, and have an automated system later send the message on my behalf once it was approved, rather than directly sending it myself.
Marking something as approved for sending (1) admits the possibility that I make further revisions to the message, and (2) internally relieves myself of some of the responsibility of sending the message. Of course, I am still fully responsible for the message and I accept this responsibility, but nevertheless that perception of decreased responsibility is a relaxing feeling that makes message sending easier.
It also (3) prevents me from actively waiting for replies to come it, a behavior I&amp;rsquo;d like to avoid. It does this because my messages go out without my awareness in the moment, so I cannot sit refreshing or watching for new messages. This way I don&amp;rsquo;t need to expend effort diverting my attention away from waiting for messages; my own unawareness has taken care of this for me.
So, having this &amp;ldquo;approve for delayed send&amp;rdquo; model for dealing with GGCs would be appreciated.&lt;/p&gt;
&lt;h3 id=&#34;tooling-for-struggle-2&#34;&gt;Tooling for Struggle #2&lt;/h3&gt;
&lt;p&gt;Struggle #2 has psychological components, but is also more directly about capabilities.&lt;/p&gt;
&lt;p&gt;The psychological bit:
Keeping up with 200 messages per hour isn&amp;rsquo;t even desirable. Why? It&amp;rsquo;s not that it&amp;rsquo;s a lot of noise &amp;ndash; though sometimes there is a lot of noise.
But even when there&amp;rsquo;s a lot of high quality interesting fun messages, it&amp;rsquo;s not stuff I&amp;rsquo;m actively looking to read or learn about or people that I&amp;rsquo;m choosing to keep in touch with. Instead, it&amp;rsquo;s whatever the group collectively has steered toward.
I&amp;rsquo;d rather be more intentional about what I read and discuss, rather than being at the whims of 200+ people, many of whom I haven&amp;rsquo;t met.
However, there is tension between that desire for intentionality and the desire to hear folks&#39; interesting ideas and share my own.
Adding to the tension further is a natural inclination toward reading messages as they come in, because they&amp;rsquo;re attention-grabbing even if they aren&amp;rsquo;t where I&amp;rsquo;d like to place my focus.&lt;/p&gt;
&lt;p&gt;The capabilities bit:
Even if I decided I did want to stay abreast of the conversation, there&amp;rsquo;s simply too much to reasonably process.
People are discussing topics about which I have a lot to learn.
I don&amp;rsquo;t have the bandwidth to think deeply &amp;ndash; or even shallowly &amp;ndash; about what folks are saying, while also maintaining normal human functions.&lt;/p&gt;
&lt;p&gt;So, what tooling can help?&lt;/p&gt;
&lt;p&gt;Summarization:
A machine learning system that categorizes messages by topic would be super helpful.
It could send a weekly digest listing the topics discussed, and clicking on a topic could bring me to a summary of the messages, with the option to drill down into the individual messages.&lt;/p&gt;
&lt;p&gt;Notification settings:
Right now I&amp;rsquo;ve simply turned off all notifications. If I could turn back on notifications for specific topics, that would be nice. E.g. &amp;ldquo;notify me if people start talking about programming tools again, but only if we haven&amp;rsquo;t talked about programming tools in at least a day since the last time you notified me.&amp;rdquo; This type of notification seems straightforward to build combining my Messager system with LLMs. Perhaps I&amp;rsquo;ll give it a go.&lt;/p&gt;
&lt;p&gt;Messenger UI: Even with notifications disabled, GGCs appear first in my list of Messenger chats because FB orders them by message recency, and GGCs always have a recent message. I&amp;rsquo;d prefer a way to keep them out of this default view, so I can see genuine conversations with individual people in their place.&lt;/p&gt;
&lt;p&gt;Browsing UI: The existing UI is unhelpful for trying to get an overview of the conversation. There&amp;rsquo;s a lot of whitespace, so only a few messages are visible at once. Replies for different topics are all mixed together.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If you&amp;rsquo;re working on anything like the toolings mentioned here, don&amp;rsquo;t hesitate to get in touch. There&amp;rsquo;s a Discussions section below, or feel free to ping me in a GGC!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning Journal of Hypotheses</title>
      <link>https://davidbieber.com/snippets/2021-11-05-hypothesis-arxiv/</link>
      <pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2021-11-05-hypothesis-arxiv/</guid>
      
      <description>&lt;p&gt;This snippet is about an idea for a new venue for publishing research hypotheses before any experiments have been carried out.
We can think of the idea as a &amp;ldquo;Hypothesis Journal&amp;rdquo; or &amp;ldquo;Hypothesis Arxiv&amp;rdquo;. Similar to how arxiv.org hosts pre-prints for scholarly articles, the Hypothesis Arxiv would be a venue for researchers to submit their research hypotheses for the research community to see and evaluate. As I&amp;rsquo;m interested in having this venue serve as a place for the community to not only submit, but also discuss and evaluate the hypotheses, &amp;ldquo;Hypothesis OpenReview&amp;rdquo; might be an even more fitting title.&lt;/p&gt;
&lt;p&gt;To narrow the scope of discussion, let&amp;rsquo;s confine ourselves to thinking about machine learning research for the time being. My hope is that such a venue would allow the machine learning community to more thoughtfully select the set of hypotheses it focuses on from year to year.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll aim to cover (1) why this is a good idea, (2) what it might look like, and (3) I&amp;rsquo;ll try to preempt some concerns one might have. We&amp;rsquo;ll also take a quick look at (4) similar ideas that have been tried in the past, and what we can learn from them.&lt;/p&gt;
&lt;h3 id=&#34;the-machine-learning-hypotheses-journal&#34;&gt;The &amp;ldquo;Machine Learning Hypotheses&amp;rdquo; Journal&lt;/h3&gt;
&lt;p&gt;The &amp;ldquo;Hypothesis Journal&amp;rdquo; idea is for a new venue that accepts scholarly submissions from researchers in the form of hypotheses, rather than complete research papers.
A hypothesis is generally a simpler and shorter artifact than a research paper.
Whereas a research paper includes a hypothesis together with experiments, their results, analysis, and conclusions, a hypothesis paper stops short of performing the proposed experiments.
It still contains the background and motivation, hypothesis, and proposed experiments, but does not perform those experiments, gather any new data, or form any conclusions about the veracity of the hypothesis.&lt;/p&gt;
&lt;p&gt;Once hypothesis papers are submitted, they are assigned reviewers.
Reviewers evaluate hypothesis along various dimensions for their scientific merit, allowing those hypothesis that seem most promising (e.g. interesting, plausible and potentially surprising, ethical, and likely impactful) to rise to the top.&lt;/p&gt;
&lt;p&gt;In addition to the standard review period, an important piece of the idea is opening up discussion to the machine learning community at large. The difference here is that the official reviewers are selected because they are trusted experts in the same field as the hypothesis paper, whereas the public discussion is open to anyone.&lt;/p&gt;
&lt;p&gt;The hope is that through the expert reviews and the community discussions, strong hypotheses can be identified and rewarded, and all hypotheses can see sunlight that allows them both to improve and inspire.&lt;/p&gt;
&lt;p&gt;Since hypothesis papers take less effort and less time to produce, a researcher might produce and submit several hypothesis papers to the &amp;ldquo;Hypothesis Journal&amp;rdquo; in a single cycle. I am also hopeful that each hypothesis can be assigned a greater number of reviewers than conference papers typically are.
This would allow the variance of the reviewer pool to diminish a little, and for each hypothesis to receive valuable signal from a variety of reviewers as to its merits.&lt;/p&gt;
&lt;p&gt;To make the idea concrete, let&amp;rsquo;s call the journal &amp;ldquo;Machine Learning Hypotheses&amp;rdquo;. And let&amp;rsquo;s further say it has an annual submission deadline, and a short review cycle followed by a conference.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;The pace of machine learning research is accelerating. Certain types of machine learning research are becoming increasingly expensive to perform (e.g. training large scale language models), prohibitively so for some researchers. A result of this is that there are far more hypotheses to test than resources available to test them. So, choosing wisely what hypotheses we investigate is increasingly important.&lt;/p&gt;
&lt;p&gt;The current publication model incentives publication of complete results.
Researchers come together at conferences to discuss findings. It&amp;rsquo;s at this point that the most significant mixing of ideas occurs.
In a flow diagram, the scientific process looks like roughly like this, with the greatest discussion and mixing of ideas currently taking place at the point marked (), while I am proposing increasing our focus on the point marked ():&lt;/p&gt;
&lt;p&gt;[Observations (from scientific literature, experiments, etc.)]
&lt;br/&gt; [Hypothesis ()]
&lt;br/&gt; [Experiments]
&lt;br/&gt; [Results]
&lt;br/&gt;Path 1:  [Success]  [Write up paper ()]
&lt;br/&gt;Path 2:  [Failure ()]  [Go to start. Revise Hypothesis]&lt;/p&gt;
&lt;p&gt;(): It is primarily at (), when a hypothesis has been confirmed, that the research community comes together en masse to discuss the findings. This takes place through publications, conferences, and journals.&lt;/p&gt;
&lt;p&gt;(): I have seen proposed on several occasions that there be more opportunities for publishing negative results, and I support these proposals. That amounts to greater discussion taking place at (), e.g. through the introduction of &amp;ldquo;Negative Result Journals&amp;rdquo;. This is not what I am proposing though; I am proposing increasing our community focus on (), when hypotheses are formed but not yet tested.&lt;/p&gt;
&lt;p&gt;(): My proposal is that we have a forum for publishing and evaluating hypotheses, even before experiments have been run and data has been collected, thereby increasing the amount of discussion of ideas that takes place at the spot marked () in the ongoing cycle of the scientific method.&lt;/p&gt;
&lt;p&gt;The main benefit of increasing publication and discussion at the hypothesis stage of the scientific process is the potential to &lt;strong&gt;more selectively and thoughtfully shape the collective portfolio of hypotheses that the research community as a whole pursues&lt;/strong&gt;. It does this through a few mechanisms. I would summarize them as (1) &lt;strong&gt;quantity&lt;/strong&gt;: increasing the range and number of ideas generated, (2) &lt;strong&gt;quality&lt;/strong&gt; and (3) &lt;strong&gt;coordination&lt;/strong&gt;: improving the quality and diversity of research pursued through discussion, and (4) &lt;strong&gt;speed&lt;/strong&gt;: tightening the feedback loop between when an idea is generated and when downstream ideas based on it are generated.&lt;/p&gt;
&lt;h5 id=&#34;1-quantity&#34;&gt;(1) Quantity&lt;/h5&gt;
&lt;p&gt;It is much easier to submit a hypothesis than to submit a full research paper. Therefore a &amp;ldquo;hypothesis arxiv&amp;rdquo; or &amp;ldquo;hypothesis journal&amp;rdquo;, if adequately popular and prestigious, could substantially increase the number of ideas proposed and discussed widely compared with the number seen in publications today.&lt;/p&gt;
&lt;p&gt;Compared with writing up a hypothesis, actually performing experiments, collecting data, performing analysis, and drawing conclusions is a considerable amount of work. Some individual researchers might be able to submit a few times, up to perhaps a full order of magnitude, more high quality hypotheses than complete research projects. These might include ideas the researcher would never have time to pursue fully on their own, but which the community could benefit from greatly.&lt;/p&gt;
&lt;p&gt;By attaching credit and prestige to submitting hypothesis, we make it possible to split the role of researcher into two sub-roles. One sub-rule is the idea generator/&amp;ldquo;hypothesizer&amp;rdquo;, and the other is the &amp;ldquo;experimentalist&amp;rdquo;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; that evaluates the hypothesis. This would enable some researchers to specialize into one of these two categories (while many researchers could continue operating both roles concurrently). Today, a successful research career requires mastering both of these skill sets. A prestigious &amp;ldquo;hypothesis journal&amp;rdquo; could reduce this pressure, perhaps allowing for people to make careers out of just one skill set of the other, more than is possible today.&lt;/p&gt;
&lt;p&gt;Importantly, researchers would be able to submit hypotheses about experiments that they may be unable to carry out on their own. Take the case of training large language models as an example. This is a prohibitively expensive task for many research organizations. Even if you cannot train a large language model yourself, you can still learn about them and produce informed hypotheses about them.
So, the best ideas about large language models could come from someone not in a position to run the experiments themselves.
The &amp;ldquo;hypothesis arxiv&amp;rdquo; idea would allow these researchers to still play a vital role in the research process.
This idea could significantly expand the number of researchers who can participate in large language model research, even if many of them can only participate at the hypothesis stage&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h5 id=&#34;2-quality&#34;&gt;(2) Quality&lt;/h5&gt;
&lt;p&gt;By moving the discussion of hypotheses as a community earlier in the cycle of the scientific method, we can be more selective and focused in what hypotheses we dedicate significant resources to.
Ideas that are obviously true or obviously false can be identified by the review process; these ideas need not consume significant effort by the community. The best ideas will be identified as such, and lower quality ideas can improve through the feedback they receive during review and discussion. By getting more viewpoints involved in selecting and evaluating ideas, the best ideas (to a wider range of researchers) will rise to the top and garner more attention.&lt;/p&gt;
&lt;p&gt;When a hypothesis finally is confirmed or rejected, since it will already have been discussed by the community, we will also have a &lt;em&gt;more accurate idea of how surprising the result truly is&lt;/em&gt;. Without this discussion first, we can only use hindsight to estimate how surprising findings are. This is an important idea, which other research communities adopt partially through the concept of pre-registration, but which is somewhat lacking in machine learning research today.&lt;/p&gt;
&lt;h5 id=&#34;3-coordination&#34;&gt;(3) Coordination&lt;/h5&gt;
&lt;p&gt;Putting hypotheses out in public before running experiments also allows for improved coordination. In particular, it can &lt;em&gt;decrease overlap&lt;/em&gt; in ideas pursued. This can in turn allow more different research directions to be pursued.&lt;/p&gt;
&lt;p&gt;Additionally, improved coordination can allow for the formation of larger efforts around the most promising directions. For example, if a researcher proposes a large language model experiment that is promising but which they cannot evaluate themself, a large research org might choose to work directly with that researcher to collaboratively evaluate the hypothesis.&lt;/p&gt;
&lt;h5 id=&#34;4-speed&#34;&gt;(4) Speed&lt;/h5&gt;
&lt;p&gt;There are two senses in which the hypothesis journal could accelerate the research process. One is by allowing new ideas to be born sooner, and the second is by increasing competition.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tighter iteration cycle&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Today an idea doesn&amp;rsquo;t spawn child ideas until it is published, which comes after the experiments have been run and the hypothesis evaluated.
In principle, these child ideas could be born much sooner if the hypothesis were shared sooner, even if the hypothesis has not been demonstrated true yet.
Of course the amount of downstream work that can be done is limited before a result has been confirmed, but it is limited in how limited it is.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Competition to evaluate ideas&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the &amp;ldquo;hypothesis journal&amp;rdquo; idea to work, there has to be some prestige or other motivations attached to submitting surprising, useful, high quality hypotheses that turn out to be true (or false in an interesting way). Even so, there will still be lots of motivation remaining for the groups that actually carry out the experiments and confirm or reject the hypotheses. Once a strong hypothesis paper has been submitted, the idea is public, and if it is a good idea there could be competition to evaluate the idea as quickly as possible.&lt;/p&gt;
&lt;h5 id=&#34;other-benefits&#34;&gt;Other benefits&lt;/h5&gt;
&lt;p&gt;Those four factors (quantity, quality, coordination, and speed) collectively suggest the hypothesis journal could accelerate the pace of machine learning research, and improve the quality of the collective portfolio of projects of the machine learning community. Other possible benefits of a hypothesis journal include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Increasing representation. (e.g. allowing groups to partake in the research process even when running experiments may be prohibitively expensive)&lt;/li&gt;
&lt;li&gt;Lowering the barrier to writing, thinking through thoroughly, sharing, and discussing ideas.&lt;/li&gt;
&lt;li&gt;Decoupling incentives, which could lead to more honest science. Specifically, if people are evaluating the hypotheses of others rather than their own hypotheses, then negative results suddenly become less unappealing. I could see this acting as a force that e.g. reduces p-hacking. Pre-registering ideas also comes with statistical benefits even if you&amp;rsquo;re the same person submitting the idea and doing the experimental science, because it reduces cherry-picking of results and similar effects.&lt;/li&gt;
&lt;li&gt;Decoupling the skill sets of hypothesizer from experimenter has value as well. It allows people to specialize, focusing their skill set and becoming better at their selected role.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-strong-hypothesis&#34;&gt;A Strong Hypothesis&lt;/h4&gt;
&lt;p&gt;What constitutes a complete hypothesis? What feedback can reviewers / the community provide about a hypothesis?&lt;/p&gt;
&lt;p&gt;When a researcher submits a &amp;ldquo;hypothesis paper&amp;rdquo;, it should be similar to a research paper that stops abruptly after proposing experiments, rather than continuing on to execute the experiments and analyze the results.&lt;/p&gt;
&lt;p&gt;It should include the hypothesis, stated precisely in a falsifiable way. It should motivate why it is a reasonable thing to believe, and why the authors expect it to be true, as well as why we do not already know that it is true. It should propose specific experiments, that in principle could be carried out (although perhaps at a budget exceeding that of the authors) to evaluate the hypothesis. It should include in the description of the experiments precisely what would be measured and why.&lt;/p&gt;
&lt;p&gt;My description here is perhaps a bit myopic, and the types of hypotheses researchers might submit might not conform to this set of criteria precisely, but I hope this conveys the sense of hypotheses that I have in mind. In a future snippet I can think at greater length about exactly what criteria make for a strong hypothesis.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a short incomplete checklist of ways a reviewer or the public might evaluate a submitted hypothesis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you believe it is true/false? Elaborate.&lt;/li&gt;
&lt;li&gt;Is it precisely stated?&lt;/li&gt;
&lt;li&gt;Is it feasible to evaluate? Does the proposed evaluation actually evaluate the hypothesis?&lt;/li&gt;
&lt;li&gt;Is it ethical?&lt;/li&gt;
&lt;li&gt;Is it worthwhile to pursue?
&lt;ul&gt;
&lt;li&gt;Cost&lt;/li&gt;
&lt;li&gt;Impact&lt;/li&gt;
&lt;li&gt;Downstream research unlocked&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Is it interesting / surprising?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The notion of &amp;ldquo;likely to be surprising&amp;rdquo; is interesting, and is an important one for a strong hypothesis.&lt;/p&gt;
&lt;h4 id=&#34;implementation-details&#34;&gt;Implementation details&lt;/h4&gt;
&lt;p&gt;As I mused in the introduction, &amp;ldquo;Hypothesis OpenReview&amp;rdquo; may be a more fitting name for the idea than &amp;ldquo;Hypothesis Arxiv&amp;rdquo;, and a journal or conference named &amp;ldquo;Machine Learning Hypotheses&amp;rdquo; is an appealing way to frame the venue for me. Perhaps OpenReview is already well suited for this idea. Instead of developing a new website, one possible implementation is to organize a new &lt;em&gt;conference&lt;/em&gt;, with submissions collected and discussed on OpenReview, where the gimmick of the conference is as discussed in this snippet: the authors need not perform the experiments they advocate for.&lt;/p&gt;
&lt;p&gt;How do we get people to (A) submit hypotheses, (B) review hypotheses, and (C) do both in a scholarly manner? The first step is to circulate this idea so we can discuss and improve upon it. If we can gather support (either for the idea as is, or a future modified version of it), from well respected researchers, their support could be instrumental in getting a &amp;ldquo;hypothesis journal&amp;rdquo; off the ground.&lt;/p&gt;
&lt;h4 id=&#34;similar-ideas&#34;&gt;Similar ideas&lt;/h4&gt;
&lt;p&gt;I&amp;rsquo;m aware of three ideas most similar to this one that have been tried in the past.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Grants&lt;/li&gt;
&lt;li&gt;Preregistration&lt;/li&gt;
&lt;li&gt;Medical Hypotheses&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;em&gt;grant application process&lt;/em&gt; is similar in many ways to the submission of a hypothesis paper. We can probably learn quite a bit from this process to inform how we implement the hypothesis journal idea. The key difference between our idea and a grant application is that there is not financing attached to submission of a hypothesis in our idea, and the person submitting a hypothesis need not be the same person who eventually evaluates it.&lt;/p&gt;
&lt;p&gt;Certain fields have a practice of pre-registration. In this practice, researchers publicly commit to a research plan before beginning the research. Wikipedia suggests preregistration can reduce p-hacking, publication bias, data dredging, inappropriate post hoc analysis, and HARKing. A hypothesis journal can have many similar benefits as preregistration. A key difference between submitting a hypothesis and pre-registering a research plan is that submitting a hypothesis does not commit you to performing the research, and in fact it may be appropriate for someone else (or no one at all) to perform the hypothesis evaluation, rather than its author.&lt;/p&gt;
&lt;p&gt;Finally there is one journal &lt;em&gt;Medical Hypotheses&lt;/em&gt; that has a similar motivation (albeit less similar than the journal&amp;rsquo;s name suggests) to our hypothesis journal idea. &lt;em&gt;Medical Hypotheses&lt;/em&gt; was designed to allow discussion of unconventional ideas, which is a different goal than we are pursuing. Like with our idea, the experiments to validate the ideas need not be run yet. This journal published controversial papers on AIDS denialism, and for most of its existence largely forwent peer review.
We can probably learn quite a bit from the history of &lt;em&gt;Medical Hypotheses&lt;/em&gt;. One lesson is that peer review and the publication of hypotheses are orthogonal; I suggest we keep peer review, while still encouraging the submission of hypotheses before they have been evaluated.&lt;/p&gt;
&lt;h4 id=&#34;concerns&#34;&gt;Concerns&lt;/h4&gt;
&lt;p&gt;In my brainstorming, I anticipate a handful of potential concerns about the idea.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flag-planting&lt;/li&gt;
&lt;li&gt;Scooping&lt;/li&gt;
&lt;li&gt;Prestige / Motivation for participation&lt;/li&gt;
&lt;li&gt;Collapsing of the idea space (need divergence and convergence; don&amp;rsquo;t want to be left with an overabundance of convergence and insufficient divergence)&lt;/li&gt;
&lt;li&gt;Ideas are a dime a dozen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Personally, I am not so concerned about &lt;em&gt;flag-planting&lt;/em&gt;. The primary purpose of the idea is to share hypotheses and inspire others to evaluate or build off of them. Flag-planting is a problem if it involves people claiming overly broad ideas prematurely so that they get future credit once the idea is more carefully analyzed and the specific instantiation of the idea that is most important comes to light.
Credit is a finicky thing, but from my perspective it is rare in modern science that full credit is attributed to a single individual or single group; the story is always more complicated. If someone proposes an overly broad hypothesis, effectively flag-planting, then perhaps they will in turn receive a portion of the credit for the specific important idea that develops from it. I do not find this objectionable. I would be curious to discuss this with you if you find flag-planting a larger concern than I am making it out to be with this idea.&lt;/p&gt;
&lt;p&gt;A fear of &lt;em&gt;scooping&lt;/em&gt; could certainly prevent people from submitting ideas to the &amp;ldquo;Machine Learning Hypothesis&amp;rdquo; journal. However, I expect that most researchers have a long line of hypotheses that they will never have the time to evaluate. So, my hope is that researchers who fear scooping could choose to keep the hypotheses they are actively working on a secret, while still opening up and sharing the many others that they possess.
For many researchers, even publishing the hypotheses that they are actively working on will be worthwhile. This allows them to get (partial) credit for the idea earlier (in effect preventing a form of scooping) than if they had to finish the research paper before submitting the idea, and it allows for earlier feedback on their research which usually leads to higher quality research overall.&lt;/p&gt;
&lt;p&gt;Next comes the issue of &lt;em&gt;motivating&lt;/em&gt; people to submit to the conference. I think that we could actually make this conference the most interesting and most fun of the machine learning conferences. Discussing half-baked ideas with researchers is always enjoyable, and I am optimistic a significant fraction of the ML research community could enjoy both submitting to this journal, and reviewing for it, because doing both is a great exercise in research creativity. Prestige and funding are other motivators for researchers; I do not think a hypothesis journal could ever be as prestigious as typical top ML conferences, but I do think that with the backing of strong players and institutions in the research community, sufficient prestige could be attached to strong submissions to the conference/journal.&lt;/p&gt;
&lt;p&gt;The next concern is about &lt;em&gt;collapsing of the idea space&lt;/em&gt;. In order for a group to come up with the best possible ideas, there needs to be space for the group&amp;rsquo;s thinking to diverge, as well as space for discussion leading to some amount of convergence on good ideas. The hypothesis journal idea increases the amount of convergence. Some might argue we actually need more divergence in our thinking. I would be interested to discuss this with you if you have this concern.&lt;/p&gt;
&lt;p&gt;Finally, a possible concern is that hypotheses without experiments are not on their own valuable, e.g. that &amp;ldquo;ideas are a dime a dozen&amp;rdquo;. To address this concern, I think we merely need to raise the bar about what constitutes a good hypothesis. We&amp;rsquo;re not looking for just any old idea, but rather ones that will advance the science of machine learning, backed up by the evidence the machine learning community has collected, and likely to be impactful on future science. Coming up with a good hypothesis is not easy, but a popular hypothesis journal could be an effective tool for improving our collective ability to do so.&lt;/p&gt;
&lt;p&gt;If you share these concerns of have additional ones not discussed here, please get in touch. I&amp;rsquo;d love to discuss.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;I describe the &amp;ldquo;hypothesis arxiv&amp;rdquo; idea using the language of empirical science, but in principle the idea could be applied to entirely theoretical fields as well. In that setting, the idea would be to make space for unproven conjectures to be shared more freely. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;And if a hypothesis submitted to the hypothesis arxiv by one group is being evaluated by another group, then it would make sense to me to include the first group closely in the evaluation process. In this way, the &amp;ldquo;hypothesis arxiv&amp;rdquo; may open up LLM research even more than described in the main text. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning and Automation Ideas for Note-taking</title>
      <link>https://davidbieber.com/snippets/2021-10-28-ml-and-automation-for-note-taking/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2021-10-28-ml-and-automation-for-note-taking/</guid>
      
      <description>&lt;p&gt;Let&amp;rsquo;s consider machine learning first, and then automation. For each we brainstorm the potential value for note-taking.&lt;/p&gt;
&lt;h3 id=&#34;the-value-of-markmachine-learningmark-for-note-taking&#34;&gt;The Value of &lt;mark&gt;Machine Learning&lt;/mark&gt; for Note-Taking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic &lt;strong&gt;transcription&lt;/strong&gt; of audio notes
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Speaker identification&lt;/strong&gt; during meetings or conversations&lt;/li&gt;
&lt;li&gt;Resurfacing of action items, surfacing relevant information, and performing actions (e.g running a google search or sending a message) in response to audio cues during meetings or conversations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Automatic &lt;strong&gt;categorization&lt;/strong&gt; of notes&lt;/li&gt;
&lt;li&gt;Automatic &lt;strong&gt;categorization of spaced repetition&lt;/strong&gt; flash cards&lt;/li&gt;
&lt;li&gt;Automatic &lt;strong&gt;context-filling&lt;/strong&gt; of spaced repetition flash cards
&lt;ul&gt;
&lt;li&gt;e.g. highlight a phrase to create a flash card; the necessary context is pulled in from surrounding paragraphs to make a coherent standalone flash card.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Automatic &lt;strong&gt;connections&lt;/strong&gt; and graph construction:
&lt;ul&gt;
&lt;li&gt;Textual elements:
&lt;ul&gt;
&lt;li&gt;Entity extraction from notes (&amp;ldquo;implicit nodes&amp;rdquo;, e.g. &amp;ldquo;Bank of America&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;Attribute extraction from notes (e.g. &amp;ldquo;incredible presentation by Pierre-Antoine&amp;rdquo; gets tagged as incredible or wow (the canonical form).)&lt;/li&gt;
&lt;li&gt;Relationship extraction (e.g. &amp;ldquo;Diamond Age by Neal Stephenson&amp;rdquo; -&amp;gt; creates an &amp;ldquo;author of&amp;rdquo; relationship)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Background knowledge elements:
&lt;ul&gt;
&lt;li&gt;e.g. knowing that Diamond Age is a book&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Writing prompt generator / &lt;strong&gt;Writing assistant&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overlap detection&lt;/strong&gt; between people&amp;rsquo;s graphs
&lt;ul&gt;
&lt;li&gt;The Go Note Go &amp;ldquo;clink&amp;rdquo; scenario&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autocomplete&lt;/strong&gt; (e.g. gmail tab completion)&lt;/li&gt;
&lt;li&gt;Improved &lt;strong&gt;spaced repetition algorithms&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Mistake detection / &lt;strong&gt;fact checking&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summarization&lt;/strong&gt; of notes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight extraction&lt;/strong&gt; from notes&lt;/li&gt;
&lt;li&gt;Suggesting &lt;strong&gt;new ideas&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Suggesting &lt;strong&gt;new online resources&lt;/strong&gt; to read / explore
&lt;ul&gt;
&lt;li&gt;Incl. articles, papers, YouTube videos, Suggesting &lt;strong&gt;people to reach out to&lt;/strong&gt; (e.g. because of their blog or Twitter or other things they&amp;rsquo;re written)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic search&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conversational chat bots&lt;/strong&gt; for exploring the knowledge in a notebase&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-value-of-markautomationmark-for-note-taking&#34;&gt;The Value of &lt;mark&gt;Automation&lt;/mark&gt; for Note-Taking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Share notes&lt;/strong&gt; with people via their preferred messaging platform&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Snooze notes&lt;/strong&gt; and ideas so you review them later&lt;/li&gt;
&lt;li&gt;Set pomodoros, alarms, and reminders to &lt;strong&gt;stay focused&lt;/strong&gt; and &lt;strong&gt;stay on task&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Note-taking &lt;strong&gt;via highlights&lt;/strong&gt; (e.g. with Browserflow)&lt;/li&gt;
&lt;li&gt;Note-taking &lt;strong&gt;via screenshots&lt;/strong&gt; (e.g. from YouTube)&lt;/li&gt;
&lt;li&gt;Automatic creation of &lt;strong&gt;spaced repetition from highlights&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bulk refactors&lt;/strong&gt; of note-taking&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pulling in context&lt;/strong&gt; from other sources (e.g. Warmly pulls LinkedIn info into Calendar, notes could pull info from wikipedia)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sync notes&lt;/strong&gt; between other sources and your notebase
&lt;ul&gt;
&lt;li&gt;Other people&amp;rsquo;s notes&lt;/li&gt;
&lt;li&gt;Your email client, calendar, TODO app, spaced repetition app, GitHub issues, other messaging services, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Publishing&lt;/strong&gt; of notes to a webpage (either publicly or privately), or to social media&lt;/li&gt;
&lt;li&gt;New &lt;strong&gt;data entry&lt;/strong&gt; mechanisms: &lt;strong&gt;Go Note Go&lt;/strong&gt;, terminal, email, text, browsing history, location history, terminal history, IoT devices, etc&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spaced repetition&lt;/strong&gt; for studying&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inactivity reminders&lt;/strong&gt; (e.g. &amp;ldquo;it&amp;rsquo;s been three months since you&amp;rsquo;ve done a music activity&amp;rdquo;, or &amp;ldquo;it&amp;rsquo;s been over 6 months since you&amp;rsquo;ve spoken with David Dohan&amp;rdquo;, or &amp;ldquo;it&amp;rsquo;s been over a year since you&amp;rsquo;ve written about microbiology.&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>GPT-3 for Spaced Repetition</title>
      <link>https://davidbieber.com/snippets/2021-09-08-gpt-3-for-spaced-repetition/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2021-09-08-gpt-3-for-spaced-repetition/</guid>
      
      <description>&lt;p&gt;Lately I&amp;rsquo;ve been using Browserflow to create spaced repetition flashcards quickly while browsing the internet.&lt;/p&gt;
&lt;p&gt;To create a card, I highlight a bit of text and press &amp;ldquo;c&amp;rdquo;. This copies the sentence containing the highlight into the card, with the part I highlighted masked out.
It&amp;rsquo;s a cloze task, as in a masked language model.
If instead I push &amp;ldquo;b&amp;rdquo;, it copies the full paragraph containing the highlight, again with the highlight masked out.&lt;/p&gt;
&lt;p&gt;Usually this is a great way to quickly create my flashcards. However, sometimes I get sentences where the subject is unclear without context, e.g. &amp;ldquo;this&amp;rdquo; in &amp;ldquo;Usually this is a great way to quickly create the flashcards.&amp;rdquo; For these, it would be great to automatically rewrite the sentence with the subject pulled in from the surrounding context.&lt;/p&gt;
&lt;p&gt;For example, &amp;ldquo;Usually this is a great way to quickly create the flashcards&amp;rdquo; could be rewritten as &amp;ldquo;Usually &lt;mark&gt;using &amp;ldquo;b&amp;rdquo; and &amp;ldquo;c&amp;rdquo; with Browserflow&lt;/mark&gt; is a great way to quickly create the flashcards.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;As a second example, consider this 
&lt;a href=&#34;http://hyperphysics.phy-astr.gsu.edu/hbase/Solar/meteor.html#c3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HyperPhysics page on the Murchison Meteorite&lt;/a&gt;. Speaking about the Murchison Meteorite, the page says &amp;ldquo;Seventy four amino acids were found in it, compared to the 20 which are characteristic of life.&amp;rdquo; I&amp;rsquo;d love to make a card saying &amp;ldquo;Seventy four &lt;mark&gt;amino acids&lt;/mark&gt; were found in the Murchison Meteorite, compared to the 20 which are characteristic of life.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;However, if I highlight &lt;mark&gt;amino acids&lt;/mark&gt; and press &amp;ldquo;c&amp;rdquo;, the generated card instead reads: &amp;ldquo;Seventy four &lt;mark&gt;amino acids&lt;/mark&gt; were found in &lt;em&gt;it&lt;/em&gt;, compared to the 20 which are characteristic of life.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;So, the challenge I present you with is: write a program that takes a sentence, and it&amp;rsquo;s surrounding context, and rewrites the sentence so that it is clear even out of context.&lt;/p&gt;
&lt;p&gt;Having played with GPT-3 and Codex recently, this seems well within the scope of large pretrained language models. I expect that with some careful prompting, a large language model could excel at this task without even any fine-tuning, just taking advantage of few shot learning. Is this the best or simplest approach? Likely it isn&amp;rsquo;t, but it may be the approach that minimizes development time and is easiest to repurpose for other similar (or dissimilar) projects in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Codex as a Programming Language</title>
      <link>https://davidbieber.com/snippets/2021-08-16-codex-pl/</link>
      <pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2021-08-16-codex-pl/</guid>
      
      <description>&lt;p&gt;In the 
&lt;a href=&#34;https://www.youtube.com/watch?v=SGUCcjHTmGY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;impressive demo of OpenAI&amp;rsquo;s &lt;em&gt;Codex&lt;/em&gt; programming system&lt;/a&gt;,
the presenters suggest that Codex enables natural language to be used as a new kind of programming language.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how that might look, followed by one problem with the suggestion.&lt;/p&gt;
&lt;p&gt;A natural-language programmer writes natural language prompts, and Codex transforms them into source code.
The Codex model is made deterministic, such that rerunning the model on the prompts always produces the same source code.
The user can make further modifications to the source code that the model produces.
The result is two parallel streams of text: (1) the natural language, and (2) the final source code.
These parallel streams can be saved in version control, shared, modified, remixed, and run.&lt;/p&gt;
&lt;p&gt;A non-programmer might still be able to make modifications, simply by modifying the natural language text, without making modifications to the source code at all.
This could be a way to learn a bit about programming for the curious non-programmer too, as they can observe the changes to the source code
that result from changing the natural language text.&lt;/p&gt;
&lt;p&gt;It is tempting to think that only the diff between the source code produced by the model and the final source code need be stored.
However, this doesn&amp;rsquo;t hold up. The prompt when generating source code includes all earlier source code in the file. So if a programmer wants to modify
a natural language prompt or piece of code earlier in a file, it could invalidate all the generated code later in the file. Rerunning the model on the new state of the program wouldn&amp;rsquo;t reproduce the source code verbatim, even with the model made deterministic.&lt;/p&gt;
&lt;p&gt;The editor showing the program might be modified to reflect this. I envision it showing two columns, the left column with natural language text and the right column, aligned with the left, showing the source code. A block of text and code shows with a green background if the model, when run on the text, produces exactly the source code on the right. It shows with yellow if the source code produced by the model differs slightly from the actual code in the block (and the diff is highlighted). And it shows in red if no simple diff distinguishes the model&amp;rsquo;s output from the actual code in the block.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Derivative of Softmax and the Softmax Cross Entropy Loss</title>
      <link>https://davidbieber.com/snippets/2020-12-12-derivative-of-softmax-and-the-softmax-cross-entropy-loss/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2020-12-12-derivative-of-softmax-and-the-softmax-cross-entropy-loss/</guid>
      
      <description>&lt;p&gt;Write $y_i = \text{softmax}(\textbf{x})_i = \frac{e^{x_i}}{\sum e^{x_d}}$.&lt;/p&gt;
&lt;p&gt;That is, $\textbf{y}$ is the softmax of $\textbf{x}$. Softmax computes a normalized exponential of its input vector.&lt;/p&gt;
&lt;p&gt;Next write $L = -\sum t_i \ln(y_i)$. This is the softmax cross entropy loss. $t_i$ is a 0/1 target representing whether the correct class is class $i$. We will compute the derivative of $L$ with respect to the inputs to the softmax function $\textbf{x}$.&lt;/p&gt;
&lt;p&gt;We have $\frac{dL}{dx_j} = -\sum t_i \frac{1}{y_i} \frac{dy_i}{d{x_j}}$ from the chain rule.&lt;/p&gt;
&lt;p&gt;We compute $\frac{dy_i}{dx_j}$ using the quotient rule.&lt;/p&gt;
&lt;p&gt;If $i = j$, this gives:&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = \frac{\sum e^{x_d} \cdot e^{x_i} - e^{x_i} \cdot e^{x_i}}{(\sum e^{x_d})^2}$&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = \frac{e^{x_i}}{\sum e^{x_d}} \cdot \left(\frac{\sum e^{x_d} - e^{x_i}}{\sum e^{x_d}}\right)$&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = y_i \cdot (1 - y_i)$&lt;/p&gt;
&lt;p&gt;If $i \ne j$, this gives:&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = \frac{\sum e^{x_d} \cdot 0 - e^{x_i} \cdot e^{x_j}}{(\sum e^{x_d})^2}$&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = -\frac{e^{x_i}}{\sum e^{x_d}} \cdot \frac{e^{x_j}}{\sum e^{x_d}} $&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = -y_i y_j$&lt;/p&gt;
&lt;p&gt;Together these equations give us the derivative of the softmax function:&lt;/p&gt;
&lt;p&gt;$\frac{dy_i}{dx_j} = \begin{cases} y_i \cdot (1 - y_i) &amp;amp; i=j \\\ -y_i y_j &amp;amp; i \ne j \end{cases}$&lt;/p&gt;
&lt;p&gt;Using this result, we can finish computing the derivative of $L$. This gives:&lt;/p&gt;
&lt;p&gt;$\frac{dL}{dx_j} = -\sum t_i \frac{1}{y_i} \frac{dy_i}{d{x_j}} = \sum\limits_i \begin{cases} t_i (y_i - 1) &amp;amp; i=j \\\ t_i y_j &amp;amp; i \ne j \end{cases}$&lt;/p&gt;
&lt;p&gt;Since exactly one of the $t_i$s is 1 and the rest are zeros this further simplifies to:&lt;/p&gt;
&lt;p&gt;$\frac{dL}{dx_j} = y_j - t_j$&lt;/p&gt;
&lt;p&gt;We have computed the derivative of the softmax cross-entropy loss $L$ with respect to the inputs to the softmax function.&lt;/p&gt;
&lt;p&gt;This page is an experiment in publishing directly from Roam Research. &lt;del&gt;It is incomplete, and the formatting is probably all wonky. Bear with me while I get this sorted.&lt;/del&gt; Update (December 13th, 2020): The formatting looks good now!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing with GPT-3</title>
      <link>https://davidbieber.com/snippets/2020-07-22-writing-with-gpt3/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://davidbieber.com/snippets/2020-07-22-writing-with-gpt3/</guid>
      
      <description>&lt;p&gt;GPT-3 is a language model developed at Open AI, and I&amp;rsquo;ve been having a lot of fun playing with it. In fact, I&amp;rsquo;ve written this post in collaboration with GPT-3. See if you can spot which parts are written by me and which parts come from GPT-3.&lt;/p&gt;
&lt;h2 id=&#34;part-1-brainstorming&#34;&gt;Part 1: Brainstorming&lt;/h2&gt;
&lt;p&gt;The first thing I did when I got access to GPT-3 is use it to brainstorm uses for GPT-3. I gave it these 5 ideas:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Explain mathematics more simply (why is X true?)&lt;/li&gt;
&lt;li&gt;Generate programs from input/output examples&lt;/li&gt;
&lt;li&gt;Generate questions about a paper I read&lt;/li&gt;
&lt;li&gt;Create a list of machine translation tips and tricks&lt;/li&gt;
&lt;li&gt;Create an adventure game&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And it came back with 15 more:&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Create a list of Tor commands to run to defend against an attack&lt;/li&gt;
&lt;li&gt;Create a cheat sheet for screenwriters&lt;/li&gt;
&lt;li&gt;Generate advice for a scene&lt;/li&gt;
&lt;li&gt;Generate XKCD comics&lt;/li&gt;
&lt;li&gt;Create a crib sheet for an arbitrary Python API&lt;/li&gt;
&lt;li&gt;Make a list of movies to watch&lt;/li&gt;
&lt;li&gt;Make a list of scholarly algorithms/heuristics worth reading&lt;/li&gt;
&lt;li&gt;Make a list of generic questions about Pedagogy&lt;/li&gt;
&lt;li&gt;Make a list of cognitive exercises&lt;/li&gt;
&lt;li&gt;Show patterns generated by awesome people&lt;/li&gt;
&lt;li&gt;Generate small cooking tasks&lt;/li&gt;
&lt;li&gt;Generate characters for a project&lt;/li&gt;
&lt;li&gt;Generate configuration options&lt;/li&gt;
&lt;li&gt;Generate flashcards&lt;/li&gt;
&lt;li&gt;Organize my computer/files&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And then 15 more:&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Explain things to my parents via messenger&lt;/li&gt;
&lt;li&gt;Explain things to my children via messenger&lt;/li&gt;
&lt;li&gt;Explain mathematical algorithms&lt;/li&gt;
&lt;li&gt;Automated interface design&lt;/li&gt;
&lt;li&gt;Mechanize a Nagihara Kan Airlines website&lt;/li&gt;
&lt;li&gt;Clickbait generator&lt;/li&gt;
&lt;li&gt;Music description (Herbie Hancock is playing &amp;ldquo;Dolphin Dance&amp;rdquo; live in London on the 18th March 1968)&lt;/li&gt;
&lt;li&gt;Tell me not to waste my time looking at x&lt;/li&gt;
&lt;li&gt;Interesting facts about Wikipedia&lt;/li&gt;
&lt;li&gt;Explain something to someone while my attention is elsewhere&lt;/li&gt;
&lt;li&gt;Detect adverts in x&lt;/li&gt;
&lt;li&gt;Image caption/caption game&lt;/li&gt;
&lt;li&gt;Speculate about the true utility function of x&lt;/li&gt;
&lt;li&gt;Auto-generate tests for a program&lt;/li&gt;
&lt;li&gt;Explain why my code is currently failing tests.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And then 15 more:&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Generate plots or character/story summaries&lt;/li&gt;
&lt;li&gt;Generate legal examples&lt;/li&gt;
&lt;li&gt;Generate words for crosswords&lt;/li&gt;
&lt;li&gt;Check my grammar&lt;/li&gt;
&lt;li&gt;Supply filler text for themed writing (horror, sci-fi etc.)&lt;/li&gt;
&lt;li&gt;Explain why an AI can&amp;rsquo;t read (can it comprehend metaphors?)&lt;/li&gt;
&lt;li&gt;Provide entertaining answers to obscure questions&lt;/li&gt;
&lt;li&gt;Get writing ideas and generate word combinations&lt;/li&gt;
&lt;li&gt;Create background for an NPC I need for a D&amp;amp;D game&lt;/li&gt;
&lt;li&gt;Help a sick writer generate plots&lt;/li&gt;
&lt;li&gt;Input pre-generated (from books etc.) phrases and use them for literary analysis&lt;/li&gt;
&lt;li&gt;Help explain a mathematical proof&lt;/li&gt;
&lt;li&gt;Develop a game/story/character I need&lt;/li&gt;
&lt;li&gt;Make short stories I can &amp;ldquo;overlay&amp;rdquo; on a fictional Universe I&amp;rsquo;ve created (ala Ready Player One)&lt;/li&gt;
&lt;li&gt;Make a short film/audio drama&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What a lovely list of lists of ideas! I wonder how many of these ideas are novel.&lt;/p&gt;
&lt;p&gt;Some of these ideas are outside the scope of what GPT-3 can do. For example, generating XKCD comics seems too difficult. Others are duplicates, such as &amp;ldquo;Explain mathematical algorithms&amp;rdquo; (duplicate of &amp;ldquo;Explain mathematics more simply&amp;rdquo;). And still others don&amp;rsquo;t make sense &amp;ndash; &amp;ldquo;Mechanize a Nagihara Kan Airlines website&amp;rdquo;? Overall though, solid set of ideas.&lt;/p&gt;
&lt;h2 id=&#34;part-2-mathematics&#34;&gt;Part 2: Mathematics&lt;/h2&gt;
&lt;p&gt;Once I&amp;rsquo;d gotten GPT-3 to do some brainstorming, I realized I&amp;rsquo;d need to test its capabilities before trying its suggestions out in earnest.&lt;/p&gt;
&lt;p&gt;I taught it how to evaluate simple expressions and take derivatives.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the first prompt I used:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Question: f(x) = x*x. Compute f(3).
f(3) = 3*3
f(3) = 9
Answer: 9

Question: h(x) = x*x - 2x. Compute h(5).
h(5) = 5*5 - 2*5
h(5) = 25 - 10
h(5) = 15
Answer: 15

Question: y(x) = x**3 - 2x. Compute y(3).
y(3) = 3**3 - 2*3
y(3) = 3*3*3 - 6
y(3) = 27 - 6
y(3) = 21
Answer: 21

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I could then ask it any of the following, and it would correctly show its work.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Question: f(x) = tan(x) + 1. Compute f(0).
Question: f(x) = sqrt(x) + 1. Compute f(16).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I tried to give it&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Question: f(x) = x/2 + 2. Compute f(f(16)).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;it treated it as just &lt;code&gt;Compute f(16)&lt;/code&gt; rather than &lt;code&gt;f(f(16))&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Interestingly this works:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Question: f(x) = x*x. Compute f(3).
f(3) = 3*3
f(3) = 9
Answer: 9

Question: h(x) = x*x - 2x. Compute h(5).
h(5) = 5*5 - 2*5
h(5) = 25 - 10
h(5) = 15
Answer: 15

Question: f(x) = x/2 + 2. Compute f(f(16)).
f(f(16)) = f(16/2 + 2)
f(f(16)) = f(8 + 2)
f(f(16)) = f(10)
f(f(16)) = 10/2 + 2
f(f(16)) = 5 + 2
f(f(16)) = 7
Answer: 7

Question: y(x) = x**3 - 2x. Compute y(3).
y(3) = 3**3 - 2*3
y(3) = 3*3*3 - 6
y(3) = 27 - 6
y(3) = 21
Answer: 21

Question: f(x) = x*3 - 1. Compute f(f(5)).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whereas this does not:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Question: f(x) = x*x. Compute f(3).
f(3) = 3*3
f(3) = 9
Answer: 9

Question: h(x) = x*x - 2x. Compute h(5).
h(5) = 5*5 - 2*5
h(5) = 25 - 10
h(5) = 15
Answer: 15

Question: f(x) = x*3 - 1. Compute f(f(5)).
f(f(5)) = f(5*3 - 1)
f(f(5)) = f(15 - 1)
f(f(5)) = f(14)
f(f(5)) = 14*3 - 1
f(f(5)) = 42 - 1
f(f(5)) = 41
Answer: 41

Question: y(x) = x**3 - 2x. Compute y(3).
y(3) = 3**3 - 2*3
y(3) = 3*3*3 - 6
y(3) = 27 - 6
y(3) = 21
Answer: 21

Question: f(x) = x/2 + 2. Compute f(f(16)).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After getting it to evaluate these simple expressions correctly, I also tried having it take derivatives. With an example as priming, and again having it show its work, this worked well. I haven&amp;rsquo;t performed a rigorous evaluation of its mathematical capabilities. For now, I&amp;rsquo;ve just begun to develop an intuition for how it works.&lt;/p&gt;
&lt;h2 id=&#34;part-3-playing-around&#34;&gt;Part 3: Playing Around&lt;/h2&gt;
&lt;p&gt;After doing math together, I tried many more things with GPT-3. I shared feelings with it, and it expanded on them (correctly too!). I used it to generate lists for brainstorming all manner of thing. The language model wrote love letters from inanimate objects. I tried to teach it to play Codenames, but with only very limited success. And I had it autocomplete previous snippets of mine, and had some fun cowriting with it. While I won&amp;rsquo;t be sharing all of this with you, I do have one thing to share.&lt;/p&gt;
&lt;p&gt;This is a love letter written by a frying pan:&lt;/p&gt;
&lt;p&gt;I may not seem like much to you right now. I&amp;rsquo;m coated in grease and I&amp;rsquo;m starting to rust, but really, I have big plans. I&amp;rsquo;m going to Italian restaurants. I&amp;rsquo;ll hang out with the finest (and healthiest) ingredients you can imagine. It was good knowing you, but you were never mine to keep. I&amp;rsquo;m going to cook the kind of meal you&amp;rsquo;ll dream about for the rest of your life. Good luck, sweetheart. You&amp;rsquo;ll need it.&lt;/p&gt;
&lt;h2 id=&#34;overall-principles&#34;&gt;Overall Principles&lt;/h2&gt;
&lt;p&gt;Getting an intuition for how GPT-3 behaves has been interesting, and I&amp;rsquo;ll try now to distill that intuition down into a few principles.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GPT-3 is continuing your writing, not having a dialog with you.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;ve seen on Twitter lots of people asking GPT-3 questions, and sharing its response. Know that GPT-3 continues whatever prompt you give it as if it had written the prompt itself, not as if it is responding to the prompt. This is why you often see prompts like &amp;ldquo;The following is a conversation between X and Y:&amp;rdquo;.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;GPT-3 effectively puts your writing in a made up context.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you give GPT-3 a small prompt, such a single sentence, then there are many contexts in which that prompt could be interpreted. GPT-3 is trained to marginalize over the contexts in which the text could appear. Once you start decoding GPT-3&amp;rsquo;s response though, one implicit context has been selected. It might not be the context that you intended when writing your prompt.&lt;/p&gt;
&lt;p&gt;This can happen even if you try to set the context yourself explicitly. For example you might be trying to generate a conversation or a list, and GPT-3 might decide that this conversation or list is taking place inside of a novel.&lt;/p&gt;
&lt;p&gt;You can mitigate this context switch by using a longer prompt, or by doing more of the writing yourself.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;GPT-3 likes lists and repeated structures.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the main principle behind using GPT-3 for few shot learning. Prompt GPT-3 with a few examples of performing a task, and it will usually make an effort to perform that task yet again.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;GPT-3 cannot perform linguistic tricks like unscrambling words&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It doesn&amp;rsquo;t seem capable of generating new puns (I haven&amp;rsquo;t tried this yet).
And it doesn&amp;rsquo;t seem capable of unscrambling words (I did try this, and I couldn&amp;rsquo;t even get it to unscramble 4-letter words).&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;GPT-3 benefits from &amp;ldquo;showing its work&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In my math experiments, having GPT-3 show its work was critical to getting it solving the math questions correctly. It seems that doing a single step of expression evaluation at a time is an easier task than doing it all at once. Providing examples with the steps gave GPT-3 a clearer explanation of the task than just providing input/output examples. GPT-3 also gets additional computational steps in which to solve the problem when it takes the time to show its work.&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;GPT-3 has a great breadth of knowledge and writing styles available to it&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It can express love, write flowery prose, give advice, write technical documentation, latex, program, math, take the perspective of a toaster, and more. It&amp;rsquo;s a great tool for brainstorming both explicitly (by having it generate ideas) and through exploration (by using it to help you generate ideas yourself).&lt;/p&gt;
&lt;p&gt;Though it has all the facts from the internet at its fingertips (of all the ways to anthropomorphize GPT-3, why choose fingertips?), it is just as capable of generating falsehoods as truths. Do not mistake the text it generates as true or logically correct, even if in many circumstances it does generate correct information. When it transitions from generating truth to generating nonsense it does not give a warning that it has done so (and any truth it does generate is in a sense at least partially accidental).&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Sometimes GPT-3 makes no sense&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are things that don&amp;rsquo;t make sense that the language model assigns reasonable probabilities to. And there are things that don&amp;rsquo;t make sense, are low probability, but come up anyway either due to chance or because the model doesn&amp;rsquo;t have anything better to say. It doesn&amp;rsquo;t stop generating text just because its out of its depth. Instead, it just plods on forward, saying something as reasonable as it&amp;rsquo;s capable of, regardless of the situation it finds itself in.&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;GPT-3 mimics your style&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you prompt GPT-3 with typos it will continue with typos. If you prompt GPT-3 with florid prose, it will write florid prose. If you prompt GPT-3 with anaphora laden rhetoric, or any other style, it will continue in that style.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ll let GPT-3 wrap things up itself:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;And that brings us to the end, some thoughts on whether using GPT-3 was more or less crazy than getting a Ph.D.. I think that using GPT-3 to generate ideas was a higher form of Enlightenment than any Ph.D. I&amp;rsquo;d do that again in a heartbeat, no shortage of ideas rolling around in GPT-3&amp;rsquo;s natural language processing head.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Uh huh. Whatever, GPT-3. Whatever.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>